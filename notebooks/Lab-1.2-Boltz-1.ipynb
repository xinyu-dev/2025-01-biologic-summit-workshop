{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1.2 Using Boltz-1 model to predict protein structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprare_directory(temp, delete_old=True):\n",
    "    \"\"\"\n",
    "    Create a new directory and delete the old one if it exists\n",
    "    :param temp: str: path to the directory\n",
    "    :param delete_old: bool, whether to delete the old directory. Defaults to True.\n",
    "    \"\"\"\n",
    "    if delete_old:  \n",
    "        if os.path.exists(temp):\n",
    "            # Remove the directory and all its contents\n",
    "            shutil.rmtree(temp)\n",
    "    # Recreate the directory\n",
    "    os.makedirs(temp, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the input file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Boltz-1](https://github.com/jwohlwend/boltz/tree/main) is a state-of-the-art open-source model that predicts the 3D structure of proteins, RNA, DNA, and small molecules. It handles modified residues, covalent ligands and glycans, as well as condition the generation on pocket residues.\n",
    "\n",
    "In this lab, we will primarily look at protein structure prediction. 2 exmaple fils are provided in the `notebooks/input` directory for monomer and multimer. Let's look at the multimer example first: \n",
    "\n",
    "\n",
    "```yaml\n",
    "# notebooks/input/multimer.yaml\n",
    "version: 1  # Optional, defaults to 1\n",
    "sequences:\n",
    "  - protein:\n",
    "      id: A\n",
    "      sequence: MAHHHHHHVAVDAVSFTLLQDQLQSVLDTLSEREAGVVRLRFGLTDGQPRTLDEIGQVYGVTRERIRQIESKTMSKLRHPSRSQVLRDYLDGSSGSGTPEERLLRAIFGEKA\n",
    "  - protein:\n",
    "      id: B\n",
    "      sequence: MRYAFAAEATTCNAFWRNVDMTVTALYEVPLGVCTQDPDRWTTTPDDEAKTLCRACPRRWLCARDAVESAGAEGLWAGVVIPESGRARAFALGQLRSLAERNGYPVRDHRVSAQSA\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the structure, we will use the `boltz predict` command. \n",
    "Additional information about the command can be found using: \n",
    "\n",
    "```bash\n",
    "! boltz predict --help\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: boltz predict [OPTIONS] DATA\n",
      "\n",
      "  Run predictions with Boltz-1.\n",
      "\n",
      "Options:\n",
      "  --out_dir PATH               The path where to save the predictions.\n",
      "  --cache PATH                 The directory where to download the data and\n",
      "                               model. Default is ~/.boltz.\n",
      "  --checkpoint PATH            An optional checkpoint, will use the provided\n",
      "                               Boltz-1 model by default.\n",
      "  --devices INTEGER            The number of devices to use for prediction.\n",
      "                               Default is 1.\n",
      "  --accelerator [gpu|cpu|tpu]  The accelerator to use for prediction. Default\n",
      "                               is gpu.\n",
      "  --recycling_steps INTEGER    The number of recycling steps to use for\n",
      "                               prediction. Default is 3.\n",
      "  --sampling_steps INTEGER     The number of sampling steps to use for\n",
      "                               prediction. Default is 200.\n",
      "  --diffusion_samples INTEGER  The number of diffusion samples to use for\n",
      "                               prediction. Default is 1.\n",
      "  --write_full_pae             Whether to dump the pae into a npz file.\n",
      "                               Default is True.\n",
      "  --write_full_pde             Whether to dump the pde into a npz file.\n",
      "                               Default is False.\n",
      "  --output_format [pdb|mmcif]  The output format to use for the predictions.\n",
      "                               Default is mmcif.\n",
      "  --num_workers INTEGER        The number of dataloader workers to use for\n",
      "                               prediction. Default is 2.\n",
      "  --override                   Whether to override existing found predictions.\n",
      "                               Default is False.\n",
      "  --use_msa_server             Whether to use the MMSeqs2 server for MSA\n",
      "                               generation. Default is False.\n",
      "  --msa_server_url TEXT        MSA server url. Used only if --use_msa_server\n",
      "                               is set.\n",
      "  --msa_pairing_strategy TEXT  Pairing strategy to use. Used only if\n",
      "                               --use_msa_server is set. Options are 'greedy'\n",
      "                               and 'complete'\n",
      "  --help                       Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "! boltz predict --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the prediction with the following parameters: \n",
    "\n",
    "- input file: `input/multimer.yaml`\n",
    "- `out_dir`: Output directory to stre the result. \n",
    "- `devices`: number of GPUs. you can run `nvidia-smi` to find out how many GPUs. In here we have 1\n",
    "- `output_format`: Save the result in PDB format. \n",
    "- `use_msa_server`: Use the MSA server (Colab) to get the MSA. You can optionally provide your own MSA file, but for simplicity, we will use the server here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking input data.\n",
      "Running predictions for 1 structure\n",
      "Processing input data.\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]Generating MSA for input/adalimumab.yaml with 2 protein entities.\n",
      "\n",
      "  0%|                                      | 0/300 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "SUBMIT:   0%|                              | 0/300 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE:   0%|                            | 0/300 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE: 100%|██████████████████████| 300/300 [elapsed: 00:00 remaining: 00:00]\u001b[A\n",
      "\n",
      "  0%|                                      | 0/300 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "SUBMIT:   0%|                              | 0/300 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE:   0%|                            | 0/300 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE: 100%|██████████████████████| 300/300 [elapsed: 00:01 remaining: 00:00]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/sagemaker-user/.conda/envs/workshop/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]| WARNING: ran out of memory, skipping batch\n",
      "Predicting DataLoader 0: 100%|████████████████████| 1/1 [00:00<00:00,  1.08it/s]Number of failed examples: 1\n",
      "Predicting DataLoader 0: 100%|████████████████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "! boltz predict input/adalimumab.yaml --out_dir output --devices 1 --output_format pdb --use_msa_server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time this command it is run, it will download the model weights and cache them, and can take a while (~15 min, depending on the network speed). The second time it is run, it will read the cached weights, so it will be much faster. For the example multimer, it should take ~2 minutes to complete on a A10 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `notebooks/utput/boltz_results_multimer/predictions/multimer` directory, you should see: \n",
    "-  `multimer_model_0.pdb` file: predicted structure\n",
    "- `confidence_multimer_model_0.json` file: confidence scores for the predicted structure\n",
    "- `plddt_multimer_model_0.npz` file: per-residue pLDDT confidence scores\n",
    "\n",
    "Similarly to ESMFold, assume we want to visualize the predicted structure, coloring the residues based on the pLDDT scores. To do this we will first need to extract the pLDDT scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .npz file that contains the pLDDT scores\n",
    "npz_file_path = \"output/boltz_results_multimer/predictions/multimer/plddt_multimer_model_0.npz\"\n",
    "data = np.load(npz_file_path)\n",
    "# extract the pLDDT scores\n",
    "plddt_scores = data['plddt']\n",
    "\n",
    "# how many scores are there?\n",
    "print(plddt_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the length of the PLDDt scores = length if the input sequence A (112 aa) +  input sequence B (116 aa) = 228 aa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the scores\n",
    "plddt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the min and max values of the pLDDT scores, we can see that the scores are between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(max(plddt_scores), min(plddt_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, for consistency with the ESMFold method, we will multiply the pLDDT scores by 100 to get the scores between 0 and 100. This line of code is shown in the `load_protein_boltz` function later in the nobeook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results with py3Dmol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we have seen above, to visaulize the protein, we need to match the pLDDT scores to the correct residues in the PDB file. \n",
    "\n",
    "Now open the `multimer_model_0.pdb` file and take a look at the raw PDB file. \n",
    "\n",
    "Start counting columns from 0: \n",
    "\n",
    "- `column 1`: atom number, starting from 1\n",
    "- `Column 4`: this the chain ID: A or B\n",
    "- `Column 5`: this is the residue number counting from 1 to 112 for chain A and 1 to 116 for chain B\n",
    "\n",
    "This tells us our strategy could be: \n",
    "- read the PDB file line by line\n",
    "- split each line by column\n",
    "- Look at `column 1` (0 indexed), if it is not \"ATOM\", ignore the line\n",
    "- Extract the residue number from `column 5` (0 indexed), and match it to the pLDDT score\n",
    "- Style each atom in this residue based on the pLDDT score\n",
    "\n",
    "Based on this, we will rewrite the `load_protein_boltz` function to visualize the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py3Dmol\n",
    "def load_protein_boltz(pdb_file_path, plddt_file_path, width=800, height=600):\n",
    "\n",
    "    \"\"\"\n",
    "    Load a protein structure from a PDB file and display it using py3Dmol\n",
    "    pdb_file_path: str, path to the PDB file\n",
    "    plddt_file_path: str, path to the npz file containing the pLDDT scores\n",
    "    width: int, width of the viewer in pixels\n",
    "    height: int, height of the viewer in pixels\n",
    "    return: py3Dmol.view object\n",
    "    \"\"\"\n",
    "    \n",
    "    # load the pdb file\n",
    "    with open(pdb_file_path) as ifile:\n",
    "        pdb_data = \"\".join([x for x in ifile])\n",
    "\n",
    "    # load the plddt scores\n",
    "    scores = np.load(plddt_file_path)['plddt']\n",
    "    \n",
    "    view = py3Dmol.view(width=width, height=height)\n",
    "    view.addModelsAsFrames(pdb_data)\n",
    "    \n",
    "\n",
    "    for line in pdb_data.split(\"\\n\"):\n",
    "\n",
    "        # split each line by columns\n",
    "        split = line.split()\n",
    "\n",
    "        # not a valid line, ignore\n",
    "        if len(split) == 0 or split[0] != \"ATOM\":\n",
    "            continue\n",
    "\n",
    "        # get residue id, pdb is 1-indexed, python is 0-indexed, therefore -1 to convert\n",
    "        residue_idx = int(split[5]) - 1 \n",
    "\n",
    "        # get the pLDDT score for the current residue, scale it to 0-100\n",
    "        plddt_score = scores[residue_idx] * 100\n",
    "\n",
    "        if plddt_score > 90:\n",
    "            color = \"blue\"\n",
    "        elif 70 <= plddt_score <= 90:\n",
    "            color = \"cyan\"\n",
    "        elif 50 <= plddt_score < 70:\n",
    "            color = \"yellow\"\n",
    "        else:\n",
    "            color = \"orange\"\n",
    "        \n",
    "        # Atom serial numbers typically start from 1, similar to requirement of `view.setStyle`, hence idx should be used directly\n",
    "        idx = int(split[1])\n",
    "        \n",
    "        # Style should be set per atom id\n",
    "        view.setStyle({'model': -1, 'serial': idx}, {\"cartoon\": {'color': color}})\n",
    "    view.zoomTo()\n",
    "    return view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = load_protein_boltz(\n",
    "    pdb_file_path=\"output/boltz_results_multimer/predictions/multimer/multimer_model_0.pdb\", \n",
    "    plddt_file_path=\"output/boltz_results_multimer/predictions/multimer/plddt_multimer_model_0.npz\")\n",
    "view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
